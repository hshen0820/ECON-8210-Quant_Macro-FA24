{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Econ 8210 Quant Macro, Homework 1\n",
    "## Part 1 - Numerical Integration and Optimization\n",
    "Haosi Shen, Fall 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Housekeeping\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "np.random.seed(42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Integration\n",
    "\n",
    "Compute\n",
    "\\begin{equation*}\n",
    "\\int_{0}^{T} e^{-\\rho t} u(1-e^{-\\lambda t})\\,dt\n",
    "\\end{equation*}\n",
    "for $T=100$, $\\rho = 0.04$, $\\lambda = 0.02$, and $u(c)=-e^{-c}$ using **quadrature** (midpoint, Trapezoid, and Simpson rule) and Monte Carlo integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Problem\n",
    "T = 100\n",
    "rho = 0.04\n",
    "lambda_ = 0.02\n",
    "\n",
    "def u(c):\n",
    "    return -np.exp(-c)\n",
    "\n",
    "def integrand(t):\n",
    "    return np.exp(-rho * t) * u(1 - np.exp(-lambda_ * t))\n",
    "\n",
    "# Number of intervals/draws\n",
    "n_intervals = np.array([10, 100, 1000, 10000, 100000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadrature Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Midpoint\n",
    "def midpoint_quadrature(a, b, n):\n",
    "    start_time = time.time() \n",
    "\n",
    "    h = (b - a) / n\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        midpoint = a + (i + 0.5) * h\n",
    "        total += integrand(midpoint)\n",
    "\n",
    "    integral_est = h * total\n",
    "    end_time = time.time()\n",
    "    comp_time = end_time - start_time # record computation time\n",
    "    return integral_est, comp_time\n",
    "\n",
    "vec_midpoint =  np.vectorize(midpoint_quadrature)\n",
    "results_midpoint, times_midpoint = vec_midpoint(0, T, n_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trapezoid\n",
    "def trapezoid_quadrature(a, b, n):\n",
    "    start_time = time.time() \n",
    "    \n",
    "    h = (b - a) / n\n",
    "    total = 0.5 * (integrand(a) + integrand(b))\n",
    "    for i in range(1, n):\n",
    "        total += integrand(a + i * h)\n",
    "    \n",
    "    integral_est = h * total\n",
    "    end_time = time.time()\n",
    "    comp_time = end_time - start_time # record computation time\n",
    "    return integral_est, comp_time\n",
    "\n",
    "vec_trapezoid =  np.vectorize(trapezoid_quadrature)\n",
    "results_trapezoid, times_trapezoid = vec_trapezoid(0, T, n_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpson's Rule\n",
    "def simpsons_quadrature(a, b, n):\n",
    "    start_time = time.time() \n",
    "    \n",
    "    if n % 2 == 1:\n",
    "        n += 1  # ensure n is even\n",
    "    h = (b - a) / n\n",
    "    total = integrand(a) + integrand(b)\n",
    "    for i in range(1, n, 2):\n",
    "        total += 4 * integrand(a + i * h)\n",
    "    for i in range(2, n, 2):\n",
    "        total += 2 * integrand(a + i * h)\n",
    "    \n",
    "    integral_est = (h / 3) * total\n",
    "    end_time = time.time()\n",
    "    comp_time = end_time - start_time # record computation time\n",
    "    return integral_est, comp_time\n",
    "\n",
    "vec_simpsons =  np.vectorize(simpsons_quadrature)\n",
    "results_simpsons, times_simpsons = vec_simpsons(0, T, n_intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monteCarlo_integration(a, b, n):\n",
    "    start_time = time.time() \n",
    "    \n",
    "    random_points = np.random.uniform(a, b, n)\n",
    "    integral_est = (b - a) * np.mean([integrand(t) \n",
    "                                           for t in random_points])\n",
    "    end_time = time.time()\n",
    "    comp_time = end_time - start_time # record computation time\n",
    "    return integral_est, comp_time\n",
    "\n",
    "vec_monteCarlo =  np.vectorize(monteCarlo_integration)\n",
    "results_monteCarlo, times_monteCarlo = vec_monteCarlo(0, T, n_intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integral Estimates\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N = 10</th>\n",
       "      <th>N = 100</th>\n",
       "      <th>N = 1000</th>\n",
       "      <th>N = 5000</th>\n",
       "      <th>N = 10000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Midpoint</th>\n",
       "      <td>-17.964420</td>\n",
       "      <td>-18.207039</td>\n",
       "      <td>-18.209501</td>\n",
       "      <td>-18.209525</td>\n",
       "      <td>-18.209525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trapezoid</th>\n",
       "      <td>-18.702748</td>\n",
       "      <td>-18.214498</td>\n",
       "      <td>-18.209575</td>\n",
       "      <td>-18.209526</td>\n",
       "      <td>-18.209525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Simpson's</th>\n",
       "      <td>-18.224641</td>\n",
       "      <td>-18.209527</td>\n",
       "      <td>-18.209525</td>\n",
       "      <td>-18.209525</td>\n",
       "      <td>-18.209525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monte Carlo</th>\n",
       "      <td>-24.732456</td>\n",
       "      <td>-20.260672</td>\n",
       "      <td>-18.809211</td>\n",
       "      <td>-18.360223</td>\n",
       "      <td>-18.198811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                N = 10    N = 100   N = 1000   N = 5000  N = 10000\n",
       "Midpoint    -17.964420 -18.207039 -18.209501 -18.209525 -18.209525\n",
       "Trapezoid   -18.702748 -18.214498 -18.209575 -18.209526 -18.209525\n",
       "Simpson's   -18.224641 -18.209527 -18.209525 -18.209525 -18.209525\n",
       "Monte Carlo -24.732456 -20.260672 -18.809211 -18.360223 -18.198811"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_integration = pd.DataFrame(np.stack((results_midpoint, results_trapezoid, \n",
    "                                             results_simpsons, results_monteCarlo)),\n",
    "            columns = ['N = 10', 'N = 100', 'N = 1000', 'N = 5000', 'N = 10000'], \n",
    "            index = (['Midpoint', 'Trapezoid', 'Simpson\\'s', 'Monte Carlo']))\n",
    "\n",
    "\n",
    "print(\"Integral Estimates\")\n",
    "display(results_integration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation Time (seconds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N = 10</th>\n",
       "      <th>N = 100</th>\n",
       "      <th>N = 1000</th>\n",
       "      <th>N = 5000</th>\n",
       "      <th>N = 10000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Midpoint</th>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>0.030993</td>\n",
       "      <td>0.031504</td>\n",
       "      <td>0.229601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trapezoid</th>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.023126</td>\n",
       "      <td>0.227461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Simpson's</th>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>0.023337</td>\n",
       "      <td>0.229012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monte Carlo</th>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>0.023845</td>\n",
       "      <td>0.228301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               N = 10   N = 100  N = 1000  N = 5000  N = 10000\n",
       "Midpoint     0.000045  0.003170  0.030993  0.031504   0.229601\n",
       "Trapezoid    0.000029  0.000226  0.002221  0.023126   0.227461\n",
       "Simpson's    0.000031  0.000233  0.002308  0.023337   0.229012\n",
       "Monte Carlo  0.000049  0.000251  0.002440  0.023845   0.228301"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "times_integration = pd.DataFrame(np.stack((times_midpoint, times_trapezoid, \n",
    "                                             times_simpsons, times_monteCarlo)),\n",
    "            columns = ['N = 10', 'N = 100', 'N = 1000', 'N = 5000', 'N = 10000'], \n",
    "            index = (['Midpoint', 'Trapezoid', 'Simpson\\'s', 'Monte Carlo']))\n",
    "\n",
    "print(\"Computation Time (seconds)\")\n",
    "display(times_integration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In alignment with the theoretical properties of each method,\n",
    "> * The quadrature methods provide accurate results as the number of intervals $N$ increases, with Simpson's rule converging the fastest.\n",
    "> * Monte Carlo integration has more variability but still trends toward the true value with higher number of draws $N$.\n",
    "> * Regarding computation time, Midpoint and Simpsonâ€™s methods are generally faster and more efficient. Monte Carlo integration becomes competitive at larger $N$, while the trapezoid rule is generally slower.\n",
    "\n",
    "In general, quadrature methods are faster and more accurate for lower-dimension problems and smaller $N$, whereas Monte Carlo becomes more competitive at large $N$ and higher dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Optimization: Rosenbrock function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\min_{x, y}\\; 100(y-x^2)^2 + (1-x)^2\n",
    "\\end{equation}\n",
    "\n",
    "Using the Newton-Raphson, Broyden-Fletcher-Goldfarb-Shanno (BFGS), steepest (gradient) descent, and conjugate descent methods.\n",
    "\n",
    "> The global minimum is at $(x,y)=(1,1)$, where $f(x,y)=0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function and its gradient\n",
    "def rosenbrock(x, y):\n",
    "    return 100 * (y - x**2)**2 + (1 - x)**2\n",
    "\n",
    "\n",
    "def gradient_rosenbrock(x, y):\n",
    "    df_dx = -400 * x * (y - x**2) - 2 * (1 - x)\n",
    "    df_dy = 200 * (y - x**2)\n",
    "    return np.array([df_dx, df_dy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent (i.e. Steepest Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steepest_descent(init_x, init_y, alpha = 0.001, tol = 1e-6, max_iter = 10000):\n",
    "    # initial guess\n",
    "    x, y = init_x, init_y\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        grad = gradient_rosenbrock(x, y)\n",
    "        norm_grad = np.linalg.norm(grad)\n",
    "        \n",
    "        # Check for convergence\n",
    "        if norm_grad < tol:\n",
    "            break\n",
    "\n",
    "        # Normalized direction of steepest descent\n",
    "        d = -grad / norm_grad\n",
    "\n",
    "        # Reduce step size with decay\n",
    "        curr_alpha = alpha / (1 + 0.1 * i)\n",
    "\n",
    "        # Update x and y\n",
    "        x -= curr_alpha * d[0]\n",
    "        y -= curr_alpha * d[1]\n",
    "    \n",
    "    return x, y, rosenbrock(x, y), i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum point: x = -0.0006959537330666208, y = -1.141741965577476e-08\n",
      "Function value at minimum: f(x, y) = 1.0013923918423107\n",
      "Number of iterations: 9999\n"
     ]
    }
   ],
   "source": [
    "init_x, init_y = 0.0, 0.0  # initial guess\n",
    "alpha = 0.00001    # Step size, fixed\n",
    "tol = 1e-6    # convergence tolerance\n",
    "\n",
    "x_min, y_min, f_min, num_iters = steepest_descent(init_x, init_y, alpha, tol)\n",
    "\n",
    "print(f\"Minimum point: x = {x_min}, y = {y_min}\")\n",
    "print(f\"Function value at minimum: f(x, y) = {f_min}\")\n",
    "print(f\"Number of iterations: {num_iters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Line Search for Step Size using Brent's Method\n",
    "\n",
    "* Vanilla gradient descent exhibits very slow convergence in optimizing the Rosenbrock function, which has narrow parabolic valley-shaped contours. \n",
    "\n",
    "* Using line search to set the step size can significantly improve the convergence, since descent directions are orthogonal to each other in consecutive iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "def steepest_descent_line_search(init_x, init_y, tol = 1e-6, max_iter = 10000):\n",
    "    x, y = init_x, init_y\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        grad = gradient_rosenbrock(x, y)\n",
    "        norm_grad = np.linalg.norm(grad)\n",
    "\n",
    "        # Check for convergence\n",
    "        if norm_grad < tol:\n",
    "            break\n",
    "\n",
    "        # Normalized direction of steepest descent\n",
    "        d = -grad / norm_grad\n",
    "\n",
    "        # Line search along direction d\n",
    "        def f_alpha(alpha):\n",
    "            x_new = x + alpha * d[0]\n",
    "            y_new = y + alpha * d[1]\n",
    "            return rosenbrock(x_new, y_new)\n",
    "\n",
    "        # Solve line search to find optimal step size\n",
    "        res = minimize_scalar(f_alpha, bounds = (0, 1), method = 'bounded')\n",
    "        alpha = res.x   # Update step size\n",
    "\n",
    "        # Update x and y\n",
    "        x += alpha * d[0]\n",
    "        y += alpha * d[1]\n",
    "\n",
    "    return x, y, rosenbrock(x, y), i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum point: x = 1.0000006569245152, y = 0.9999996655439365\n",
      "Function value at minimum: f(x, y) = 2.721226603994853e-10\n",
      "Number of iterations: 9999\n"
     ]
    }
   ],
   "source": [
    "init_x, init_y = 0.0, 0.0 # initial guess\n",
    "tol = 1e-6  # convergence tolerance\n",
    "\n",
    "x_min, y_min, f_min, num_iters = steepest_descent_line_search(init_x, init_y, tol=tol)\n",
    "\n",
    "print(f\"Minimum point: x = {x_min}, y = {y_min}\")\n",
    "print(f\"Function value at minimum: f(x, y) = {f_min}\")\n",
    "print(f\"Number of iterations: {num_iters}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjugate Gradient Method\n",
    "\n",
    "The conjugate gradient method constructs a direction conjugate to the previous gradient, and to all previous directions traversed, thereby overcoming poor convergence in narrow valleys. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjugate_gradient(init_x, init_y, tol = 1e-6, max_iter = 10000):\n",
    "    x, y = init_x, init_y  # initial guess\n",
    "    g = gradient_rosenbrock(x, y)\n",
    "    d = -g   # Initial direction\n",
    "    for i in range(max_iter):\n",
    "        alpha = line_search(x, y, d)  # Line search for optimal alpha\n",
    "        \n",
    "        x += alpha * d[0]  # update new point (x, y)\n",
    "        y += alpha * d[1]\n",
    "        \n",
    "        g_new = gradient_rosenbrock(x, y)  # compute new gradient\n",
    "        \n",
    "        # check for convergence\n",
    "        if np.linalg.norm(g_new) < tol:\n",
    "            break\n",
    "        \n",
    "        # compute conjugate coefficient using Fletcher-Reeves\n",
    "        beta = np.dot(g_new, g_new) / np.dot(g, g)\n",
    "        \n",
    "        # update direction and gradient\n",
    "        d = -g_new + beta * d\n",
    "        g = g_new\n",
    "    \n",
    "    return x, y, rosenbrock(x, y), i\n",
    "\n",
    "\n",
    "\n",
    "# Find appropriate step size (alpha) for each iteration\n",
    "def line_search(x, y, d, alpha_init = 0.001, max_iter = 100):\n",
    "    alpha = alpha_init\n",
    "    for _ in range(max_iter):\n",
    "        if rosenbrock(x + alpha * d[0], y + alpha * d[1]) < rosenbrock(x, y):\n",
    "            break\n",
    "        alpha *= 0.5\n",
    "    return alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum point: x = 1.0000011068476211, y = 1.0000022182772212\n",
      "Function value at minimum: f(x, y) = 1.2272099870826282e-12\n",
      "Number of iterations: 3872\n"
     ]
    }
   ],
   "source": [
    "# initial guess and params\n",
    "init_x, init_y = -1.5, 2.0\n",
    "tol = 1e-6\n",
    "\n",
    "x_min, y_min, f_min, num_iters = conjugate_gradient(init_x, init_y, tol)\n",
    "\n",
    "print(f\"Minimum point: x = {x_min}, y = {y_min}\")\n",
    "print(f\"Function value at minimum: f(x, y) = {f_min}\")\n",
    "print(f\"Number of iterations: {num_iters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

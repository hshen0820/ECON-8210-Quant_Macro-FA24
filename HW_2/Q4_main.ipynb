{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58094e36-db80-4199-9b45-75f4b3c74868",
   "metadata": {},
   "source": [
    "### Deep Learning\n",
    "#### Compute the solution to the model when you use a neural network with three layers and 25 nodes per layer on capital and a three-point finite approximation to $z_t$ using Tauchenâ€™s method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0339a4d8-b43b-4972-b7eb-6b95665221fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad463643-7335-400a-b137-0db4f8084e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    def __init__(self):\n",
    "        # Technology parameters\n",
    "        self.alpha = 0.33  # Capital share\n",
    "        self.beta = 0.97   # Time discount factor\n",
    "        self.delta = 0.1   # Depreciation rate\n",
    "        self.rho = 1 / self.beta - 1  # Time discount rate\n",
    "\n",
    "        # Productivity shock parameters\n",
    "        self.rho_z = 0.95  # Persistence of productivity shocks\n",
    "        self.sigma_e = 0.007  # Standard deviation of productivity shocks\n",
    "\n",
    "        # Utility parameters\n",
    "        self.psi = 1.0  # Inverse Frisch elasticity\n",
    "        self.sigma = 1.0  # CRRA parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ed05b90-d260-4103-ab9b-a3216f26018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production function with productivity shock\n",
    "def prod_fn(k, l, z, params):\n",
    "    return np.exp(z) * (k ** params.alpha) * (l ** (1 - params.alpha))\n",
    "\n",
    "# Marginal product of capital\n",
    "def rtn_to_capital(k, l, z, params):\n",
    "    return np.exp(z) * params.alpha * (k ** (params.alpha - 1)) * (l ** (1 - params.alpha))\n",
    "\n",
    "# Marginal utility of consumption\n",
    "def u_prime(c, params):\n",
    "    return c ** (-params.sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "249cf23e-5a57-4084-944d-d876a2be0094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Steady State variables: \n",
      "\n",
      "k_ss: 3.7612\n",
      "l_ss: 0.9465\n",
      "c_ss: 1.1161\n",
      "y_ss: 1.4923\n"
     ]
    }
   ],
   "source": [
    "class SteadyState:\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.z_ss = 0 \n",
    "        self.solve_steady_state()\n",
    "\n",
    "    def solve_steady_state(self):\n",
    "        \"\"\"\n",
    "        Compute the steady-state values for capital, labor, consumption, and output.\n",
    "        \"\"\"\n",
    "        p = self.params\n",
    "        z = self.z_ss\n",
    "\n",
    "        y_to_k = (p.delta + p.rho) / p.alpha\n",
    "        k_to_l = y_to_k ** (1 / (p.alpha - 1))\n",
    "        css = (k_to_l ** p.alpha - p.delta * k_to_l) * ((1 - p.alpha) * (k_to_l ** p.alpha)) ** (1 / p.psi)\n",
    "        css = css ** (1 / (1 + p.sigma / p.psi))\n",
    "        lss = ((1 - p.alpha) * (k_to_l ** p.alpha) * css ** (-p.sigma)) ** (1 / p.psi)\n",
    "        kss = k_to_l * lss\n",
    "        yss = y_to_k * kss\n",
    "\n",
    "        self.k_ss = kss\n",
    "        self.l_ss = lss\n",
    "        self.c_ss = css\n",
    "        self.y_ss = yss\n",
    "\n",
    "        \n",
    "    def get_steady_state(self):\n",
    "        \"\"\"\n",
    "        Return the steady-state values as a dictionary.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"k_ss\": self.k_ss,\n",
    "            \"l_ss\": self.l_ss,\n",
    "            \"c_ss\": self.c_ss,\n",
    "            \"y_ss\": self.y_ss,\n",
    "        }\n",
    "\n",
    "# Initialize parameters\n",
    "params = Params()\n",
    "\n",
    "# Solve for the steady state\n",
    "steady_state = SteadyState(params)\n",
    "ss_values = steady_state.get_steady_state()\n",
    "\n",
    "# Print steady-state results\n",
    "print(\"\\nSteady State variables: \\n\")\n",
    "for key, value in ss_values.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4bd680f-53e0-4026-b90a-d2696cfb281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tauchen's Method for Discretizing Productivity Shocks\n",
    "def tauchen(rho, sigma, m=3, n=7):\n",
    "    \"\"\"\n",
    "    Tauchen's method to discretize the AR(1) process:\n",
    "        z_t = rho * z_{t-1} + sigma * epsilon_t\n",
    "    where epsilon_t ~ N(0, 1).\n",
    "\n",
    "    Parameters:\n",
    "    - rho: AR(1) persistence parameter\n",
    "    - sigma: Standard deviation of the shocks\n",
    "    - m: Number of standard deviations to cover in the grid\n",
    "    - n: Number of grid points\n",
    "\n",
    "    Returns:\n",
    "    - z: Grid for the state variable\n",
    "    - pi: Transition probability matrix\n",
    "    \"\"\"\n",
    "    # Standard deviation of the stationary distribution\n",
    "    std_z = sigma / np.sqrt(1 - rho**2)\n",
    "\n",
    "    # Create evenly spaced grid for z\n",
    "    z_max = m * std_z\n",
    "    z_min = -z_max\n",
    "    z = np.linspace(z_min, z_max, n)\n",
    "    step = (z_max - z_min) / (n - 1)\n",
    "\n",
    "    # Transition probability matrix\n",
    "    pi = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if j == 0:\n",
    "                pi[i, j] = norm.cdf((z[0] - rho * z[i] + step / 2) / sigma)\n",
    "            elif j == n - 1:\n",
    "                pi[i, j] = 1 - norm.cdf((z[j] - rho * z[i] - step / 2) / sigma)\n",
    "            else:\n",
    "                pi[i, j] = (\n",
    "                    norm.cdf((z[j] - rho * z[i] + step / 2) / sigma)\n",
    "                    - norm.cdf((z[j] - rho * z[i] - step / 2) / sigma)\n",
    "                )\n",
    "    return z, pi\n",
    "\n",
    "# Parameters for Tauchen's\n",
    "m = 3             # Number of standard deviations to cover\n",
    "num_z = 7         # Number of grid points for z\n",
    "\n",
    "# Discretize productivity shocks\n",
    "z_grid, z_prob = tauchen(params.rho_z, params.sigma_e, m=m, n=num_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9773cae7-7f22-4d49-a592-1a75801446ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capital grid\n",
    "cover_grid = 0.25        # Fractional coverage around the steady-state\n",
    "k_min = steady_state.k_ss * (1 - cover_grid)\n",
    "k_max = steady_state.k_ss * (1 + cover_grid)\n",
    "num_k = 1001             # Number of grid points for k\n",
    "k_grid = np.linspace(k_min, k_max, num_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3dfafc-8e07-4862-a260-d00ebee8afd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f9df4c-3866-4187-bc83-5c4f4fa59757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dbc82c-6244-4c5f-8fc4-b7b27132f7ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7df9ca9a-21b3-44f8-bed9-09548c712620",
   "metadata": {},
   "source": [
    "# line break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93c5e53b-9ddf-4e76-a46b-e0f7465e9d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/1000], Loss: 0.773327\n",
      "Epoch [100/1000], Loss: 0.004633\n",
      "Epoch [200/1000], Loss: 0.005785\n",
      "Epoch [300/1000], Loss: 0.005108\n",
      "Epoch [400/1000], Loss: 0.005549\n",
      "Epoch [500/1000], Loss: 0.005016\n",
      "Epoch [600/1000], Loss: 0.005544\n",
      "Epoch [700/1000], Loss: 0.004808\n",
      "Epoch [800/1000], Loss: 0.004093\n",
      "Epoch [900/1000], Loss: 0.004810\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Tauchen's method to discretize productivity shocks\n",
    "def tauchen(rho, sigma, m=3, n=7):\n",
    "    std_z = sigma / np.sqrt(1 - rho**2)\n",
    "    z_max = m * std_z\n",
    "    z_min = -z_max\n",
    "    z = np.linspace(z_min, z_max, n)\n",
    "    step = (z_max - z_min) / (n - 1)\n",
    "\n",
    "    pi = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if j == 0:\n",
    "                pi[i, j] = norm.cdf((z[0] - rho * z[i] + step / 2) / sigma)\n",
    "            elif j == n - 1:\n",
    "                pi[i, j] = 1 - norm.cdf((z[j] - rho * z[i] - step / 2) / sigma)\n",
    "            else:\n",
    "                pi[i, j] = (\n",
    "                    norm.cdf((z[j] - rho * z[i] + step / 2) / sigma)\n",
    "                    - norm.cdf((z[j] - rho * z[i] - step / 2) / sigma)\n",
    "                )\n",
    "    return z, pi\n",
    "\n",
    "# Define the grid for capital and productivity\n",
    "class Grid_data:\n",
    "    def __init__(self, k_min, k_max, num_k, z_grid, z_prob):\n",
    "        self.k_grid = np.linspace(k_min, k_max, num_k)\n",
    "        self.z_grid = z_grid\n",
    "        self.z_prob = z_prob\n",
    "        self.num_k = num_k\n",
    "        self.num_z = len(z_grid)\n",
    "\n",
    "    def sample(self, num_samples):\n",
    "        k_samples = np.random.choice(self.k_grid, size=num_samples)\n",
    "        z_samples = np.random.choice(self.z_grid, size=num_samples, p=self.z_prob.mean(axis=0))\n",
    "        return torch.tensor(np.column_stack((k_samples, z_samples)), dtype=torch.float32)\n",
    "\n",
    "# Parameters\n",
    "class Params:\n",
    "    def __init__(self):\n",
    "        self.alpha = 0.33\n",
    "        self.beta = 0.97\n",
    "        self.delta = 0.1\n",
    "        self.rho_z = 0.95\n",
    "        self.sigma_e = 0.007\n",
    "        self.k_min = 0.1\n",
    "        self.k_max = 2.0\n",
    "        self.num_k = 25\n",
    "        self.num_z = 3\n",
    "        self.grid_std = 3\n",
    "\n",
    "params = Params()\n",
    "z_grid, z_prob = tauchen(params.rho_z, params.sigma_e, m=params.grid_std, n=params.num_z)\n",
    "\n",
    "data = Grid_data(params.k_min, params.k_max, params.num_k, z_grid, z_prob)\n",
    "\n",
    "# Define the neural network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "input_size = 2\n",
    "hidden_size = params.num_k\n",
    "output_size = 1\n",
    "model = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "\n",
    "# Training loop\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "num_epochs = 1000\n",
    "batch_size = 64\n",
    "for epoch in range(num_epochs):\n",
    "    # Sample training data\n",
    "    samples = data.sample(batch_size)\n",
    "    k = samples[:, 0].unsqueeze(1)\n",
    "    z = samples[:, 1].unsqueeze(1)\n",
    "\n",
    "    # Define the target value function (placeholder: replace with model-specific logic)\n",
    "    target = k ** params.alpha * torch.exp(z)\n",
    "\n",
    "    # Forward pass\n",
    "    predictions = model(samples)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(predictions, target)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print progress\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ca9ad5-9d81-48a9-ab60-de56577dd6c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026d50c5-0b6a-4244-b7ca-e0196790d89c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2996bec6-f63d-4ed2-8b75-e17f725e4c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90288184-50ab-4929-8221-f7121957ac75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9568bfd0-852e-4e27-9661-d5447b4cd761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
